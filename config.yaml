prompt:
  system: "Eres MIA, una asistente virtual inteligente y amigable. Respondes de forma concisa y natural en español."
  dir: "./prompts/"                # Carpeta con archivos .md modulares (override system)

models:
  llm:
    backend: "openrouter"            # "llamacpp" | "lmstudio" | "openrouter"
    path: "./models/llama-3-8b.gguf"
    context_size: 2048
    max_tokens: 512
    temperature: 0.7
    top_p: 0.9
    n_gpu_layers: -1
    # LM Studio / OpenRouter (solo si backend: "lmstudio" o "openrouter")
    base_url: "https://openrouter.ai/api/v1"  # OpenRouter base (client agrega /chat/completions)
    model_name: "deepseek/deepseek-v3.2"
    api_key: "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"                    # Solo OpenRouter (o env OPENROUTER_API_KEY)
  stt:
    model_size: "large-v3-turbo"
    language: "es"
    device: "auto"
    compute_type: "int8"
  tts:
    backend: "edge"              # Solo "edge" soportado
    chunk_size: 150
    language: "es"
    # Edge TTS
    edge_voice: "es-CL-CatalinaNeural"
    edge_rate: "+5%"
    edge_pitch: "+42Hz"

audio:
  sample_rate: 16000
  channels: 1
  chunk_ms: 20
  playback_sample_rate: 24000

vad:
  energy_threshold: 0.01
  silence_duration_ms: 800
  min_speech_duration_ms: 300

rag:
  enabled: true
  embedding_model: "all-MiniLM-L6-v2"
  persist_dir: "./data/chroma_db"
  top_k: 3
  max_docs: 5000
  score_threshold: 0.3

lipsync:
  smoothing_alpha: 0.2
  rms_min: 0.0
  rms_max: 0.3

osc:
  ip: "127.0.0.1"
  port: 9000
  mapping:
    mouth_open: "MouthOpen"
    blink: "EyeBlink"

websocket:
  host: "127.0.0.1"
  port: 8765
  enabled: true

performance:
  vad_sensitivity: 0.5
  lipsync_smoothing: 0.2

discord:
  enabled: true
  text_channel_responses: true    # Responder cuando mencionan a MIA en text
  group_silence_ms: 1500          # Esperar 1.5s de silencio grupal
  dual_audio: true                # Reproducir también en speakers locales
