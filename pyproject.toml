[project]
name = "mia"
version = "0.1.0"
description = "MIA – VTuber assistant with minimal latency"
readme = "README.md"
requires-python = ">=3.11"

dependencies = [
    "pyyaml",
    "sounddevice",
    "numpy",
    "python-osc",
    "websockets",
    "openai",
    "chromadb",
    "sentence-transformers",
    "transformers<4.44",       # Coqui TTS 0.22 requires BeamSearchScorer (removed in 4.44+)
]

[project.optional-dependencies]
dev = [
    "pytest",
]

# ══════════════════════════════════════════════════════════════
# ML dependencies -- DO NOT add to [dependencies] or extras.
# These require manual installation in order due to:
#   - CUDA-specific torch builds (PyPI only ships CPU)
#   - C++ compilation (llama-cpp-python)
#   - Version pinning (TTS <-> transformers <-> torch)
#
# Install order:
#   1. uv pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu124
#   2. uv pip install faster-whisper
#   3. uv pip install TTS
#   4. (optional) uv pip install llama-cpp-python
#
# After installing TTS, re-run step 1 -- TTS pulls in CPU torch.
# ══════════════════════════════════════════════════════════════

[project.scripts]
mia = "mia.main:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/mia"]

[tool.pytest.ini_options]
testpaths = ["tests"]

# Pin torch to CUDA index so `uv pip install` doesn't pull CPU-only from PyPI
[tool.uv.sources]
torch = { index = "pytorch-cu124" }
torchaudio = { index = "pytorch-cu124" }

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true
